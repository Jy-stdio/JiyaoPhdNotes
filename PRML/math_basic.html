

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>2. 数学基础 &#8212; 阿土的炼丹炉</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'PRML/math_basic';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. 指数族分布" href="Exponential_Family_Distribution.html" />
    <link rel="prev" title="1. PRML" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.jpg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.jpg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Jiyao Liu
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic Guides</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../basic/jupyter_book.html">1. Jupyter Book 使用指南</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">数学基础</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90intro.html">1. 矩阵分析</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E7%9F%A9%E9%98%B5/matrix_analysis.html">1.1. 矩阵与张量分析作业</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E4%BC%98%E5%8C%96intro.html">2. 优化</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E5%87%B8%E4%BC%98%E5%8C%96/%E4%BA%A4%E6%9B%BF%E5%90%91%E4%B9%98%E5%AD%90%E6%B3%95%28Alternating_Direction_Method_of_Multipliers_ADMM%29.html">2.1. 交替方向乘子法（Alternating Direction Method of Multipliers, ADMM）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E5%87%B8%E4%BC%98%E5%8C%96/20240326%20Krylov%20Subspace%20Regularization%20for%20Inverse%20Problems.html">2.2. Krylov Subspace Regularization for Inverse Problems</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E7%BB%9F%E8%AE%A1intro.html">3. 统计</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E7%BB%9F%E8%AE%A1/20240204_20%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E6%96%AD%E5%85%A5%E9%97%A8.html">3.1. Visual ML | Statistics | 20.贝叶斯推断入门</a></li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/%E7%BB%9F%E8%AE%A1/20240204_%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E6%96%AD%E8%BF%9B%E9%98%B6.html">3.2. Visual ML | Statistics | 21.深入贝叶斯推断</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">PRML notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="intro.html">1. PRML</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">2. 数学基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="Exponential_Family_Distribution.html">3. 指数族分布</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023_11_05_PGM1.html">4. 概率图模型入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%E6%80%BB.html">5. 概率图模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023_11_12_Kalman_Filter.html">6. 线性动态系统-卡曼滤波（Kalman Filter）</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023_11_15_Pacticle_Filter.html">7. Particle Filter</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">学术报告</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Report/acad_lunch_zhuang_wang.html">1. 20231016 | 庄吓海/王成彦-可解释医学影像分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Report/report-rec.html">2. VALSE 20200415 |  机器学习 vs 压缩感知：核磁共振成像与重建</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">research</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../research/evidential_regression.html">1. Evidential Learning and Uncentainty</a></li>

<li class="toctree-l1 has-children"><a class="reference internal" href="../research/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95intro.html">3. 文献阅读记录</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../research/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/202401_%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB.html">3.1. 【Paper Reading】Foundation model | 可解释性 | 图像融合 20240123</a></li>



<li class="toctree-l2"><a class="reference internal" href="../research/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/202403%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB.html">3.5. 20240303【Paper Reading】Uncertainty | 可解释性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/20230614_TV_CS.html">3.6. TV CS</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">MRI notes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../MRI%E5%8E%9F%E7%90%86/20231018_MT_CEST_NOE.html">1. MT&amp;CEST&amp;NOE 磁化转移定量成像</a></li>
<li class="toctree-l1"><a class="reference internal" href="../MRI%E5%8E%9F%E7%90%86/20230709_Parallel_MRI_reconstruction.html">2. Parallel MRI reconstruction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../MRI%E5%8E%9F%E7%90%86/20230714_Awesome%20MRI%20Recon.html">3. Awesome Accelerated-MRI-Reconstruction-Papers </a></li>

<li class="toctree-l1"><a class="reference internal" href="../MRI%E5%8E%9F%E7%90%86/20230731_MRI%E9%87%8D%E5%BB%BA%E6%96%87%E7%8C%AE%E6%95%B4%E7%90%86.html">5. 传统方法</a></li>






<li class="toctree-l1"><a class="reference internal" href="../MRI%E5%8E%9F%E7%90%86/20230725_Phase_Unwrapping_and_Background_Removal.html">12. 如何重建QSM</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Pytorch框架</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../pytorch/%E6%A8%A1%E5%9E%8B%E6%8B%93%E6%89%91%E7%BB%93%E6%9E%84.html">1. 模型拓扑结构</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/hook.html">1.1. 注册钩子函数（register_forward_hook）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/computation_graph.html">1.2. 计算图构建细节</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/torch.gather.html">1.3. Torch.gather 索引</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch/02_gelu_grad.html">1.4. GeLU介绍及使用</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../pytorch/20240528_pytorch%E5%8A%A0%E9%80%9F%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7.html">2. pytorch加速训练技巧</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">图像处理基础</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../%E5%9B%BE%E5%83%8F%28%E4%BF%A1%E5%8F%B7%29%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/20230918_%E5%8E%8B%E7%BC%A9%E6%84%9F%E7%9F%A5.html">1. 【method】稀疏与压缩感知 |  图像稀疏性及压缩感知方法白话讲解</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">深度学习基础</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/DL_intro.html">1. 深度学习基础</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">深度学习应用</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8Bintro.html">1. 生成式模型</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B/20240110_%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8BScore-based%20model%E7%B2%BE%E8%AE%B2.html">1.1. 扩散模型 | 1.Score-based model精讲</a></li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B/20240110_%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8BSDE%E7%B2%BE%E8%AE%B2.html">1.2. 扩散模型 | 2.SDE精讲</a></li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B/20240111_%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8.html">1.3. 扩散模型 | 3.Score-based SDE for accelerated MRI精讲</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E9%80%86%E9%97%AE%E9%A2%98intro.html">2. 逆问题</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E9%80%86%E9%97%AE%E9%A2%98/20230102_Diffusion_model_fo_the_inverse_problem.html">2.1. 【Method】inverse problem | 基于diffusion model的图像逆问题求解</a></li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E9%80%86%E9%97%AE%E9%A2%98/20230717_ADMM_CSNet_note.html">2.2. 【method】ADMM-CSNet |  一种图像压缩感知重建的深度学习方法（1）- 方法解析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E9%80%86%E9%97%AE%E9%A2%98/20230719_ADMM_CSNet_code.html">2.3. ADMM CSNet代码解析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E9%80%86%E9%97%AE%E9%A2%98/20230708_%E4%BD%BF%E7%94%A8%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E6%A8%A1%E5%9E%8B%E6%B1%82%E8%A7%A3%E9%80%86%E9%97%AE%E9%A2%98.html">2.4. 使用数据驱动模型求解逆问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E9%80%86%E9%97%AE%E9%A2%98/20230808_%E5%9B%BE%E5%83%8F%E9%80%86%E9%97%AE%E9%A2%98.html">2.5. 图像逆问题通用算法</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E5%8F%AF%E8%A7%A3%E9%87%8Aintro.html">3. 可解释</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E5%8F%AF%E8%A7%A3%E9%87%8AAI/20240112%E6%9B%B9%E5%8E%9F%E6%B8%AF%E5%A4%A7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E7%8E%B0%E8%B1%A1%E7%9A%84%E8%A7%A3%E9%87%8A.html">3.1. 【深度学习中的一些有趣现象及其理论解释】——曹原（香港大学）-2024</a></li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/%E5%8F%AF%E8%A7%A3%E9%87%8AAI/20240303_talk_trustworthy_AI.html">3.2. 【Talk】CVPRW 202206 | Towards robust and trustworthy AI for medical imaging - Ender Konukoglu</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">工具使用解决方案</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tools/latex_symbol.html">1. Latex常用符号表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tools/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7.html">2. 常用工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tools/20220503typora%2Bupic%2B%E9%98%BF%E9%87%8C%E4%BA%91OSS%2B%E5%9D%9A%E6%9E%9C%E4%BA%91%2B%E6%9C%89%E9%81%93%E4%BA%91%E7%AC%94%E8%AE%B0%E6%9E%84%E5%BB%BA%E4%B8%93%E5%B1%9E%E7%AC%94%E8%AE%B0%E7%B3%BB%E7%BB%9F.html">3. typora+upic+阿里云OSS+坚果云+有道云笔记构建专属笔记系统</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tools/20240202_XHR_failed.html">4. Remote-SSH XHR failed无法访问远程服务器</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Leetcode算法</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Leetcode%E7%AE%97%E6%B3%95/leetcode_Intro.html">1. Leetcode</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FPRML/math_basic.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/PRML/math_basic.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>数学基础</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2.1. 概率-高斯分布1-极大似然估计</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vs">2.2. 概率-高斯分布2-极大似然估计（无偏估计 VS 有偏估计）</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.3. 概率-高斯分布3-从概率密度函数角度观察</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.4. 概率-高斯分布4-局限性</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">2.5. 概率-高斯分布5-已知联合概率求边缘概率及条件概率</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">2.6. 概率-高斯分布6-已知边缘和条件概率求联合概率分布</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jensen-s-inequality">2.7. 概率-不等式1-杰森不等式（Jensen’s Inequality）</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">2.8. 参考</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1><span class="section-number">2. </span>数学基础<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h1>
<section id="id2">
<h2><span class="section-number">2.1. </span>概率-高斯分布1-极大似然估计<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>高斯分布在统计机器学习中占据重要的地位。本节内容主要是利用极大似然估计计算高斯分布下的最优参数。</p>
</div>
<p>假设数据<span class="math notranslate nohighlight">\(X\)</span>中有<span class="math notranslate nohighlight">\(N\)</span>个样本，每个样本<span class="math notranslate nohighlight">\(x_i\)</span>为<span class="math notranslate nohighlight">\(p\)</span>维数据（含<span class="math notranslate nohighlight">\(p\)</span>个feature），所有的样本都独立同分布于高斯分布。</p>
<div class="math notranslate nohighlight">
\[\begin{split}X = \left(x_1, x_2, \cdots, x_N\right)^T =  \begin{pmatrix} x_1^T\\ x_2^T\\ \vdots\\ x_N^T\\ \end{pmatrix}_{N \times P}\end{split}\]</div>
<p>其中，<span class="math notranslate nohighlight">\(x_i \overset{iid} \sim  N(\mu ,  \Sigma), \theta=(\mu,\Sigma)\)</span>。</p>
<p>一维高斯分布：</p>
<div class="math notranslate nohighlight">
\[suppose \ \ \ p{=}1, \theta{=}\left(\mu, \sigma ^2\right)   \ \ \ \ then \ \ \ \ \ P(x) = {1\over \sqrt{2\pi}\sigma}\exp(-{{(x-\mu)}^2\over2\sigma^2})\]</div>
<p>高维高斯分布：</p>
<div class="math notranslate nohighlight">
\[ P(x) = {1\over(2\pi)^{p\over2}\lvert\Sigma\rvert^{1\over 2}}\exp(-{1\over2}(x-\mu)^T\Sigma^{-1}(x-\mu))\]</div>
<hr class="docutils" />
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>极大似然估计</p>
</div>
<p><strong>MLE目标</strong>：<span class="math notranslate nohighlight">\(\theta _{MLE} = arg \underset{\theta} \max P\left(X| \theta \right)\)</span>，即求最优的参数<span class="math notranslate nohighlight">\(\theta\)</span>使得对于这部分数据来说，采样出现的概率最大。对于数据集X，其对数似然</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation*}\begin{split} \log P(X|\theta) &amp;= \log \displaystyle \prod _{i=1} ^{N}P(x_i|\theta)\\ &amp;=\displaystyle \sum_{i=1}^{N}\log({1\over\sqrt{2\pi}\sigma}\exp(-{(x-\mu)^2\over{2\sigma^2}}))\\ &amp;=\displaystyle \sum_{i=1}^N[\log{1\over\sqrt{2\pi}}+\log{1\over\sigma}-{(x-\mu)^2\over2\sigma^2}] \end{split}\end{equation*}\end{split}\]</div>
<blockquote>
<div><p>注意：先对<span class="math notranslate nohighlight">\(P(X|\theta)\)</span>取对数，使得后续求导计算更加方便。
因为<span class="math notranslate nohighlight">\(L(\theta)\)</span>与<span class="math notranslate nohighlight">\(\ln L(\theta)\)</span>在同一<span class="math notranslate nohighlight">\(\theta\)</span>处取到极值。</p>
</div></blockquote>
<p><strong>首先求最优的参数<span class="math notranslate nohighlight">\(\mu\)</span></strong>，求导，找出极大值：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation*} \begin{split} \mu_{MLE} &amp;= arg \underset{\mu} \max{\log P(X|\theta)}\\ &amp;=arg \underset{\mu} \max\displaystyle\sum_{i=1}^N{-{(x_i-\mu)^2\over2\sigma^2}}\\ &amp;=arg \underset{\mu} \min\displaystyle\sum_{i=1}^N{(x_i-\mu)^2}\\ \end{split}\end{equation*}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation*}\begin{split} {\partial\over\partial\mu}\displaystyle\sum_{i=1}^N(x_i-\mu)^2&amp;=\displaystyle\sum_{i=1}^N2(x_i-\mu)(-1)=0\\ \displaystyle\sum_{i=1}^N(x_i-\mu)&amp;=0\\ \displaystyle\sum_{i=1}^Nx_i-N\mu&amp;=0\\ \mu_{MLE}&amp;={1\over N}\displaystyle\sum_{i=1}^Nx_i \end{split}\end{equation*}\end{split}\]</div>
<p>故，最优<span class="math notranslate nohighlight">\(\mu = {1\over N}\displaystyle\sum_{i=1}^Nx_i\)</span>，为样本均值。此结果为<em>无偏估计</em>（样本均值是否等于期望），因为<span class="math notranslate nohighlight">\(E[\mu_{MLE}]={1\over N}\displaystyle\sum_{i=1}^NE[x_i]={1\over N}\displaystyle\sum_{i=1}^N\mu=\mu\)</span>。</p>
<p><strong>接下来求<span class="math notranslate nohighlight">\(\sigma\)</span>的最优解</strong>：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation*} \begin{split} \sigma^2_{MLE} &amp;= arg \underset{\sigma} \max\displaystyle\sum_{i=1}^N[\log{1\over\sigma}-{(x_i-\mu)^2\over2\sigma^2}]\\ &amp;=arg \underset{\sigma} \max\displaystyle\sum_{i=1}^N[-\log{\sigma}-{1\over2\sigma^2}(x_i-\mu)^2] \end{split}\end{equation*}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation*} \begin{split} {\partial\over\partial\sigma}\displaystyle\sum_{i=1}^N[-\log{\sigma}-{1\over2\sigma^2}(x_i-\mu)^2]&amp;=\displaystyle\sum_{i=1}^N[-{1\over\sigma}-{1\over2}(x_i-\mu)^2(-2){1\over\sigma^3}]=0\\ \displaystyle\sum_{i=1}^N[-{1\over\sigma}+(x_i-\mu)^2\sigma^{-3}]&amp;=0\\ \displaystyle\sum_{i=1}^N[-\sigma^2+(x_i-\mu)^2]&amp;=0\\ -N\sigma^2+\displaystyle\sum_{i=1}^N(x_i-\mu)^2&amp;=0\\ \sigma^2_{MLE}&amp;={1\over N}\displaystyle\sum_{i=1}^N(x_i-\mu_{MLE})^2 \end{split}\end{equation*}\end{split}\]</div>
<p>此结果为<em>有偏估计</em>，因为<span class="math notranslate nohighlight">\(E[\sigma^2_{MLE}]= {N-1\over N}\sigma^2\)</span>，想要得到无偏估计结果需要对结果进行放缩：<span class="math notranslate nohighlight">\(\hat {\sigma^2} = {1\over N-1}\displaystyle\sum_{i=1}^N(x_i-\mu_{MLE})^2\)</span>。这里我们给出有偏证明。</p>
</section>
<section id="vs">
<h2><span class="section-number">2.2. </span>概率-高斯分布2-极大似然估计（无偏估计 VS 有偏估计）<a class="headerlink" href="#vs" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>本节内容主要是证明<span class="math notranslate nohighlight">\(\mu_{MLE}\)</span>和<span class="math notranslate nohighlight">\(\sigma^2_{MLE}\)</span>的无偏与有偏性，并计算无偏<span class="math notranslate nohighlight">\(\sigma^2_{MLE}\)</span>。</p>
</div></blockquote>
<p>前一节得到了一维情况下的极大似然估计结果:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu_{MLE}={1\over N}\displaystyle\sum_{i=1}^Nx_i\)</span>：无偏估计</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma^2_{MLE} = {1\over N}\displaystyle\sum_{i=1}^N(x_i-\mu_{MLE})^2\)</span>： 有偏估计</p></li>
</ul>
<p>定义<strong>若<span class="math notranslate nohighlight">\(E[\hat\mu] = \mu \ \ \ \ E[\hat\sigma] = \sigma\)</span>则无偏，若不相等，则有偏。</strong> 已证<span class="math notranslate nohighlight">\(\mu_{MLE}\)</span>无偏。下面证明<span class="math notranslate nohighlight">\(\sigma^2_{MLE}\)</span>有偏：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation*} \begin{split} E[\sigma^2_{MLE}] &amp;=E[{1\over N}\displaystyle\sum_{i=1}^N(x_i-\mu_{MLE})^2]\\ &amp;=E[{1\over N}\displaystyle\sum_{i=1}^N(x_i^2-2x_i\mu_{MLE}+\mu_{MLE}^2)]\\ &amp;=E[{1\over N}\displaystyle\sum_{i=1}^Nx_i^2-2\mu_{MLE}{1\over N}\displaystyle\sum_{i=1}^Nx_i+{1\over N}\displaystyle\sum_{i=1}^N\mu_{MLE}^2]\\ &amp;=E[{1\over N}\displaystyle\sum_{i=1}^Nx_i^2-2\mu_{MLE}^2+\mu^2_{MLE}]\\ &amp;=E[{1\over N}\displaystyle\sum_{i=1}^Nx_i^2-\mu^2_{MLE}]\\ &amp;=E[{1\over N}\displaystyle\sum_{i=1}^N(x_i^2-\mu^2_{MLE})]\\ &amp;={1\over N}\displaystyle\sum_{i=1}^N(E[x_i^2]-E[\mu^2_{MLE}])\\ &amp;={1\over N}\displaystyle\sum_{i=1}^N(D[x_i]+{E[x_i]}^2-D[\mu_{MLE}]-{E[\mu_{MLE}]}^2)\\ &amp;={1\over N}\displaystyle\sum_{i=1}^N(\sigma_{MLE}^2+\mu^2-D[{1\over N}\displaystyle\sum_{i=1}^Nx_i]-\mu^2)\\ &amp;={1\over N}\displaystyle\sum_{i=1}^N(\sigma^2_{MLE}-{1\over N^2}N\sigma_{MLE}^2)\\ &amp;={N-1 \over N}\sigma_{MLE}^2 \end{split}\end{equation*}\end{split}\]</div>
<p>注意：有一步因为<span class="math notranslate nohighlight">\(D[x] = E[x^2]-{E[x]}^2\)</span>。</p>
<p>因此<span class="math notranslate nohighlight">\(\sigma^2_{MLE}\)</span>有偏，则<span class="math notranslate nohighlight">\(\sigma^2_{MLE} = {1\over N-1}\displaystyle\sum_{i=1}^N(x_i-\mu_{MLE})^2\)</span>无偏。</p>
</section>
<section id="id3">
<h2><span class="section-number">2.3. </span>概率-高斯分布3-从概率密度函数角度观察<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>本节将从高维角度来看高斯分布</p>
</div>
<p>当<span class="math notranslate nohighlight">\(x\)</span>为<span class="math notranslate nohighlight">\(p\)</span>维随机变量，定义多维高斯分布pdf为</p>
<div class="math notranslate nohighlight">
\[x\sim N(\mu,\Sigma) = {1\over(2\pi)^{p\over2}\lvert\Sigma\rvert^{1\over 2}}\exp(-{1\over2}\underbrace{(x-\mu)^T\Sigma^{-1}(x-\mu)}_{二次型})\]</div>
<p>其中，<span class="math notranslate nohighlight">\(x=\begin{pmatrix} x_1\\ x_2\\ \vdots\\ x_p\\ \end{pmatrix}\)</span>, <span class="math notranslate nohighlight">\(\mu=\begin{pmatrix} \mu_1\\ \mu_2\\ \vdots\\ \mu_p\\ \end{pmatrix}\)</span>，<span class="math notranslate nohighlight">\(\Sigma=\begin{pmatrix}  \sigma_{11}&amp;\sigma_{12}&amp;\cdots&amp;\sigma_{1p}\\ \sigma_{21}&amp;\sigma_{22}&amp;\cdots&amp;\sigma_{2p}\\  \vdots&amp;\vdots&amp;&amp;\vdots\\  \sigma_{p1}&amp;\sigma_{p2}&amp;\cdots&amp;\sigma_{pp}\\  \end{pmatrix}_{p\times p}\)</span>。</p>
<blockquote>
<div><p>通常来说，<span class="math notranslate nohighlight">\(\Sigma\)</span>是半正定的(对称的)，本节内容假设是正定的（特征值<span class="math notranslate nohighlight">\(\lambda&gt;0\)</span>）,便于叙述。首先从概率密度函数来看，<span class="math notranslate nohighlight">\(x\)</span>是自变量，因此<span class="math notranslate nohighlight">\(\exp\)</span>前面的内容为常数。</p>
</div></blockquote>
<hr class="docutils" />
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((x-\mu)^T\Sigma^{-1}(x-\mu)\)</span>：马氏距离(<span class="math notranslate nohighlight">\(x\)</span>和<span class="math notranslate nohighlight">\(\mu\)</span>之间，<span class="math notranslate nohighlight">\(\Sigma^{-1}\)</span>看做协方差矩阵的逆)</p></li>
</ul>
<blockquote>
<div><p>马氏距离：Mahalanobis Distance是一种用于测量多维空间中两个数据点之间的距离的方法，马氏距离考虑了各个特征之间的相关性，因此在具有多个特征的数据集中更为有效。注意，<span class="math notranslate nohighlight">\(\Sigma = I\)</span>时，马氏距离=欧氏距离。</p>
</div></blockquote>
<p>下面我们分析一下这种马氏距离的实际意义：对<span class="math notranslate nohighlight">\(\Sigma = U\Lambda U^T\)</span>特征值分解（<span class="math notranslate nohighlight">\(U\)</span>为正交阵），<span class="math notranslate nohighlight">\(U=(u_1,u_2,\cdots,u_p)_{p\times p}\)</span></p>
<p>则有：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation*}\begin{split} \Sigma &amp;= U\Lambda U^T\\ &amp;=(u_1,u_2,\cdots,u_p)\begin{pmatrix}  \lambda_1&amp;0&amp;\cdots&amp;0\\ 0&amp;\lambda_2&amp;\cdots&amp;\vdots\\  \vdots&amp;\vdots&amp;\ddots&amp;\vdots\\  0&amp;0&amp;\cdots&amp;\lambda_p\\  \end{pmatrix} \begin{pmatrix} u_1^T\\ u_2^T\\ \vdots\\ u_p^T \end{pmatrix}\\ &amp;=(u_1\lambda_1, u_2\lambda_2,\cdots,u_p\lambda_p)\begin{pmatrix} u_1^T\\ u_2^T\\ \vdots\\ u_p^T \end{pmatrix}\\ &amp;=\displaystyle\sum_{i=1}^p{u_i\lambda_iu_i^T} \end{split}\end{equation*} \end{split}\]</div>
<p>则：<span class="math notranslate nohighlight">\(\Sigma^{-1}=(U\Lambda U^T)^{-1}=(U^T)^{-1}\Lambda^{-1}U^{-1}=U\Lambda^{-1} U^T =\displaystyle\sum_{i=1}^p{u_i{1\over\lambda_i}u_i^T}\)</span></p>
<p>将<span class="math notranslate nohighlight">\(U^T = U^{-1}\)</span>和上式<span class="math notranslate nohighlight">\(\Sigma^{-1}\)</span>带入，令<span class="math notranslate nohighlight">\(y_i=(x-\mu)^Tu_i\)</span>，则有</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation*}\begin{split} \Delta=&amp;(x-\mu)^T\Sigma^{-1}(x-\mu)\\ =&amp;(x-\mu)^T\displaystyle\sum_{i=1}^p({u_i{1\over\lambda_i}u_i^T})(x-\mu)\\ =&amp;\displaystyle\sum_{i=1}^p({(x-\mu)^Tu_i{1\over\lambda_i}u_i^T(x-\mu)})\\ =&amp;\displaystyle\sum_{i=1}^p({y_i{1\over\lambda_i}y_i^T})\\ =&amp;\displaystyle\sum_{i=1}^p({y_i^2\over\lambda_i}) \end{split}\end{equation*}\end{split}\]</div>
<p>上面的推导意味着马氏距离经过变换成为了<span class="math notranslate nohighlight">\(\displaystyle\sum_{i=1}^p({y_i^2\over\lambda_i})\)</span>，<span class="math notranslate nohighlight">\(y_i\)</span>是<span class="math notranslate nohighlight">\(x-\mu\)</span>在特征向量<span class="math notranslate nohighlight">\(u_i\)</span>上的投影长度。</p>
<p>令<span class="math notranslate nohighlight">\(p=2\)</span>,则上式便是令<span class="math notranslate nohighlight">\(\Delta取不同值时候的同心椭圆\)</span></p>
<figure class="align-default" id="blackhole">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/MDL7BE.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/MDL7BE.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/MDL7BE.png" style="height: 300px;" /></a>
</figure>
<blockquote>
<div><p>每当<span class="math notranslate nohighlight">\(\Delta\)</span>取不同值，椭圆就相当于对这一高度的等高线，也对应一个固定的概率值。若<span class="math notranslate nohighlight">\(\lambda_i=c\)</span>(常量)时，上图便是一个圆</p>
</div></blockquote>
</section>
<section id="id4">
<h2><span class="section-number">2.4. </span>概率-高斯分布4-局限性<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h2>
<p>继上节内容，将<span class="math notranslate nohighlight">\(\Delta\)</span>代入<span class="math notranslate nohighlight">\(p(x)\)</span>：<span class="math notranslate nohighlight">\(p(x) = {1\over(2\pi)^{p\over2}\lvert\Sigma\rvert^{1\over 2}}\exp(-{1\over2}\Delta)\)</span>。每当<span class="math notranslate nohighlight">\(p(x)\)</span>取一个概率值时，都对应一个固定的<span class="math notranslate nohighlight">\(\Delta\)</span>，即如下图</p>
<figure class="align-default" id="id5">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/Zkyyj3.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/Zkyyj3.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/Zkyyj3.png" style="height: 200px;" /></a>
</figure>
<blockquote>
<div><p>每当<span class="math notranslate nohighlight">\(p(x)\)</span>取为某个概率值时，相当于水平切小山，投影到<span class="math notranslate nohighlight">\(x-y\)</span>面便是一个椭圆曲线，也是等高线。若<span class="math notranslate nohighlight">\(\Sigma\)</span>中对的对角元都相等，则称各向同性</p>
</div></blockquote>
<hr class="docutils" />
<p>高斯分布存在局限：有些数据无法用高斯分布表示，因此需要使用GMM等混合模型。</p>
</section>
<section id="id6">
<h2><span class="section-number">2.5. </span>概率-高斯分布5-已知联合概率求边缘概率及条件概率<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>本节目标：已知一个多维高斯分布的联合概率，求其边缘概率分布及条件概率分布</p>
<p>本节内容是推导最多最复杂的部分</p>
</div>
<p>已知：</p>
<div class="math notranslate nohighlight">
\[x\sim N(\mu,\Sigma) = {1\over(2\pi)^{p\over2}\lvert\Sigma\rvert^{1\over 2}}\exp(-{1\over2}{(x-\mu)^T\Sigma^{-1}(x-\mu)}), x \in \mathbb R^p\]</div>
<p>其中，<span class="math notranslate nohighlight">\(x=\begin{pmatrix} x_1\\ x_2\\ \vdots\\ x_p\\ \end{pmatrix}\)</span>, <span class="math notranslate nohighlight">\(\mu=\begin{pmatrix} \mu_1\\ \mu_2\\ \vdots\\ \mu_p\\ \end{pmatrix}\)</span>，<span class="math notranslate nohighlight">\(\Sigma=\begin{pmatrix}  \sigma_{11}&amp;\sigma_{12}&amp;\cdots&amp;\sigma_{1p}\\ \sigma_{21}&amp;\sigma_{22}&amp;\cdots&amp;\sigma_{2p}\\  \vdots&amp;\vdots&amp;&amp;\vdots\\  \sigma_{p1}&amp;\sigma_{p2}&amp;\cdots&amp;\sigma_{pp}\\  \end{pmatrix}_{p\times p}\)</span>。</p>
<p>为了简化，我们假设已知两个高维高斯分布的联合分布（将<span class="math notranslate nohighlight">\(x\)</span>看做<span class="math notranslate nohighlight">\(x_a\)</span>和<span class="math notranslate nohighlight">\(x_b\)</span>的联合概率分布）：</p>
<p><span class="math notranslate nohighlight">\(x=\begin{pmatrix} x_a\\ x_b\\ \end{pmatrix}, \mu=\begin{pmatrix} \mu_a\\ \mu_b\\ \end{pmatrix}, \Sigma=\begin{pmatrix}  \sigma_{aa}&amp;\sigma_{ab}\\ \sigma_{ba}&amp;\sigma_{bb}\\ \end{pmatrix}, (a+b=p)\)</span></p>
<p>求：<span class="math notranslate nohighlight">\(p(x_a),p(x_b|x_a)\)</span>，由对称性可得<span class="math notranslate nohighlight">\(p(x_b),p(x_a|x_b)\)</span></p>
<blockquote>
<div><p>通用方法：配方法（RPML）。今天使用另一种方法，比配方法简便</p>
</div></blockquote>
<figure class="align-default" id="id7">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/3zcMbU.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/3zcMbU.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/3zcMbU.png" style="height: 640px;" /></a>
</figure>
<figure class="align-default" id="id8">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/aCRHwY.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/aCRHwY.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/aCRHwY.png" style="height: 640px;" /></a>
</figure>
<figure class="align-default" id="id9">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/ndC19Q.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/ndC19Q.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/ndC19Q.png" style="height: 640px;" /></a>
</figure>
<figure class="align-default" id="id10">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/h5A1KN.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/h5A1KN.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/h5A1KN.png" style="height: 240px;" /></a>
</figure>
</section>
<section id="id11">
<h2><span class="section-number">2.6. </span>概率-高斯分布6-已知边缘和条件概率求联合概率分布<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="id12">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/sC2hnu.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/sC2hnu.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/sC2hnu.png" style="height: 380px;" /></a>
</figure>
<figure class="align-default" id="id13">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/IMqmt0.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/IMqmt0.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/IMqmt0.png" style="height: 580px;" /></a>
</figure>
<figure class="align-default" id="id14">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/c68tIQ.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/c68tIQ.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/c68tIQ.png" style="height: 600px;" /></a>
</figure>
<figure class="align-default" id="id15">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/m6VvVX.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/m6VvVX.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/m6VvVX.png" style="height: 600px;" /></a>
</figure>
</section>
<section id="jensen-s-inequality">
<h2><span class="section-number">2.7. </span>概率-不等式1-杰森不等式（Jensen’s Inequality）<a class="headerlink" href="#jensen-s-inequality" title="Permalink to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>杰森不等式在机器学习的推导中经常被用到，其定义如下：假设<span class="math notranslate nohighlight">\(f(x)\)</span>为凸函数，则<span class="math notranslate nohighlight">\(E[f(x)]\geq f(E[x])\)</span></p>
</div>
<p>证明如下：</p>
<figure class="align-default" id="id16">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/r8Ajlm.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/r8Ajlm.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/r8Ajlm.png" style="height: 200px;" /></a>
</figure>
<figure class="align-default" id="id17">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/2yqHuu.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/2yqHuu.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/2yqHuu.png" style="height: 400px;" /></a>
</figure>
<hr class="docutils" />
<p>实际上我们在机器学习中使用的更多的是<strong>杰森不等式的变式</strong>，如下推导</p>
<figure class="align-default" id="id18">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/bu9HuF.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/bu9HuF.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/bu9HuF.png" style="height: 200px;" /></a>
</figure>
<figure class="align-default" id="id19">
<a class="reference internal image-reference" href="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/wvhDs6.png"><img alt="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/wvhDs6.png" src="https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/wvhDs6.png" style="height: 600px;" /></a>
</figure>
</section>
<section id="id20">
<h2><span class="section-number">2.8. </span>参考<a class="headerlink" href="#id20" title="Permalink to this heading">#</a></h2>
<p>[1] <a class="reference external" href="https://www.bilibili.com/video/av32905863/">机器学习-白板推导系列-数学基础(bilibili)</a></p>
<p>[2] <a class="reference external" href="https://zhuanlan.zhihu.com/p/290876484">机器学习-白板推导系列(二)-数学基础笔记</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./PRML"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1. </span>PRML</p>
      </div>
    </a>
    <a class="right-next"
       href="Exponential_Family_Distribution.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>指数族分布</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2.1. 概率-高斯分布1-极大似然估计</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vs">2.2. 概率-高斯分布2-极大似然估计（无偏估计 VS 有偏估计）</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.3. 概率-高斯分布3-从概率密度函数角度观察</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.4. 概率-高斯分布4-局限性</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">2.5. 概率-高斯分布5-已知联合概率求边缘概率及条件概率</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">2.6. 概率-高斯分布6-已知边缘和条件概率求联合概率分布</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jensen-s-inequality">2.7. 概率-不等式1-杰森不等式（Jensen’s Inequality）</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">2.8. 参考</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Jiyao Liu
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>