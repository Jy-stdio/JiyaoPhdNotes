{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch 注册钩子函数（register_forward_hook）实现对各个层（layer）输入输出 shape 的查看\n",
    "\n",
    "参考链接：\n",
    "+ https://www.bilibili.com/video/BV1WY411N7fR\n",
    "+ https://github.com/chunhuizhang/bilibili_vlogs/tree/master/learn_torch/utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) torch.Size([4, 3, 300, 300]) => torch.Size([4, 64, 300, 300])\n",
      "ReLU(inplace=True) torch.Size([4, 64, 300, 300]) => torch.Size([4, 64, 300, 300])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([4, 64, 300, 300]) => torch.Size([4, 64, 150, 150])\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) torch.Size([4, 64, 150, 150]) => torch.Size([4, 128, 150, 150])\n",
      "ReLU(inplace=True) torch.Size([4, 128, 150, 150]) => torch.Size([4, 128, 150, 150])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([4, 128, 150, 150]) => torch.Size([4, 128, 75, 75])\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) torch.Size([4, 128, 75, 75]) => torch.Size([4, 256, 75, 75])\n",
      "ReLU(inplace=True) torch.Size([4, 256, 75, 75]) => torch.Size([4, 256, 75, 75])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) torch.Size([4, 256, 75, 75]) => torch.Size([4, 256, 75, 75])\n",
      "ReLU(inplace=True) torch.Size([4, 256, 75, 75]) => torch.Size([4, 256, 75, 75])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([4, 256, 75, 75]) => torch.Size([4, 256, 37, 37])\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) torch.Size([4, 256, 37, 37]) => torch.Size([4, 512, 37, 37])\n",
      "ReLU(inplace=True) torch.Size([4, 512, 37, 37]) => torch.Size([4, 512, 37, 37])\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) torch.Size([4, 512, 37, 37]) => torch.Size([4, 512, 37, 37])\n",
      "ReLU(inplace=True) torch.Size([4, 512, 37, 37]) => torch.Size([4, 512, 37, 37])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([4, 512, 37, 37]) => torch.Size([4, 512, 18, 18])\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) torch.Size([4, 512, 18, 18]) => torch.Size([4, 512, 18, 18])\n",
      "ReLU(inplace=True) torch.Size([4, 512, 18, 18]) => torch.Size([4, 512, 18, 18])\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) torch.Size([4, 512, 18, 18]) => torch.Size([4, 512, 18, 18])\n",
      "ReLU(inplace=True) torch.Size([4, 512, 18, 18]) => torch.Size([4, 512, 18, 18])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([4, 512, 18, 18]) => torch.Size([4, 512, 9, 9])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1)) torch.Size([4, 512, 9, 9]) => torch.Size([4, 4096, 3, 3])\n",
      "ReLU(inplace=True) torch.Size([4, 4096, 3, 3]) => torch.Size([4, 4096, 3, 3])\n",
      "Dropout(p=0.0, inplace=False) torch.Size([4, 4096, 3, 3]) => torch.Size([4, 4096, 3, 3])\n",
      "Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1)) torch.Size([4, 4096, 3, 3]) => torch.Size([4, 4096, 3, 3])\n",
      "ReLU(inplace=True) torch.Size([4, 4096, 3, 3]) => torch.Size([4, 4096, 3, 3])\n",
      "AdaptiveAvgPool2d(output_size=1) torch.Size([4, 4096, 3, 3]) => torch.Size([4, 4096, 1, 1])\n",
      "Flatten(start_dim=1, end_dim=-1) torch.Size([4, 4096, 1, 1]) => torch.Size([4, 4096])\n",
      "Dropout(p=0.0, inplace=False) torch.Size([4, 4096]) => torch.Size([4, 4096])\n",
      "Linear(in_features=4096, out_features=1000, bias=True) torch.Size([4, 4096]) => torch.Size([4, 1000])\n",
      "Identity() torch.Size([4, 1000]) => torch.Size([4, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2913, -0.2272, -0.1178,  ..., -1.1337,  0.0161,  2.1446],\n",
       "        [-1.1445, -0.1245, -0.1403,  ..., -1.1070,  0.0524,  2.0473],\n",
       "        [-1.1924, -0.0579, -0.2485,  ..., -1.0776,  0.0991,  2.3268],\n",
       "        [-1.1745, -0.0294, -0.2601,  ..., -0.8900,  0.3848,  2.4532]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def print_shape(m, i, o):\n",
    "    #m: module, i: input, o: output\n",
    "    # print(m, i[0].shape, o.shape)\n",
    "    print(m, i[0].shape, '=>', o.shape)\n",
    "\n",
    "\n",
    "def get_children(model: nn.Module):\n",
    "    # get children form model!（递归）\n",
    "    children = list(model.children())\n",
    "    flatt_children = []\n",
    "    if children == []:\n",
    "        # if model has no children; model is last child! :O\n",
    "        return model\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for child in children:\n",
    "            try:\n",
    "                flatt_children.extend(get_children(child))\n",
    "            except TypeError:\n",
    "                flatt_children.append(get_children(child))\n",
    "    return flatt_children\n",
    "\n",
    "\n",
    "model_name = 'vgg11'\n",
    "# model_name = 'resnet34'\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "flatt_children = get_children(model)\n",
    "for layer in flatt_children:\n",
    "    layer.register_forward_hook(print_shape)\n",
    "\n",
    "# for layer in model.children():\n",
    "#     layer.register_forward_hook(print_shape)\n",
    "\n",
    "# 4d: batch*channel*width*height\n",
    "batch_input = torch.randn(4, 3, 300, 300)\n",
    "\n",
    "model(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}