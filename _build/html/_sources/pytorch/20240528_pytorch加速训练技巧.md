#! https://zhuanlan.zhihu.com/p/700286389
# pytorch加速训练技巧

## 数据IO

<u>**自定义Dataset**</u>**：优先从内存中读取数据，避免从磁盘读**

+ 在`__init__`中**把数据加载到内存中**，`__getitem__`直接从内存总获取这些已加载的数据；
+ 如果数据过大，内存不够，那么可以**维持一个固定大小的内存池**，`__getitem__`偶尔从磁盘读；

**<u>优化Dataloader</u>**：

+ 若`__getitem__`包含运算，例如Transform等数据增广或预处理，则设置`num_works>0`指定使用的CPU核心数，**使用多个子进程来加速数据加载**。*注意：有时候增大num_works反而会导致训练过程阻塞变慢，原因可能是CPU资源不足、内存资源不足或数据加载和处理速度不一致（参考：[CSDN：讲解pytorch dataloader num_workers参数设置导致训练阻塞](https://blog.csdn.net/q7w8e9r4/article/details/134919387?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-134919387-blog-134675467.235^v43^pc_blog_bottom_relevance_base6&spm=1001.2101.3001.4242.1&utm_relevant_index=1)）*
+ **异步处理：**设置`pin_memory=True`并且`.cuda(non_blocking=True)`
	+ 后者表示数据CPU$\rightarrow$GPU的时候设置为异步：在传数据的时候，CPU还可以干别的事情；

**<u>开启cudnn benchmark加速卷积神经网络训练</u>**：`torch.backends.cudnn.benchmark=True`

+ cudnn中用好几种方法实现了卷积操作，设置torch.backends.cudnn.benchmark=True使得模型在训练时寻找最快的卷积操作。这样做的情况下，模型在在前几步搜索最快的操作，因此稍慢，后面阶段的训练便会大大加速
+ 在下面几种情况下加速最为明显：GPU性能较差时，模型的卷积输入/batch_size/输入的高度和宽度是固定的等，便于模型寻找最优的卷积操作

## 训练策略

**<u>DistributedDataParallel</u>**

事实证明，distributedDataParallel比DataParallel快得多，因为它只执行梯度同步的通信。所以，一个好的hack是使用distributedDataParallel替换DataParallel，**即使是在单机上进行训练**。

## 爱因斯坦标示（`einops`）与pytorch联合编写

![image-20240528110542964](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/image-20240528110542964.png)

爱因斯坦标示有非常大的优势：**<u>代码更容易理解</u>并且运行更快**

注意：

1. 下图2 out3升维的时候，需要执行某个维度，例如模型(b i)维度为6，但是并不清楚为2x3还是3x2
2. 如下图3 为 swin Transformer中image2patch的实现

代码实现：

![image-20240528142326015](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/image-20240528142326015.png)

## Reference

[1] [【36、PyTorch训练加速技巧与爱因斯坦标示法】](https://www.bilibili.com/video/BV1ZY411b78A?vd_source=225dba48b31d269151658db856705273)

[2] [CSDN：讲解pytorch dataloader num_workers参数设置导致训练阻塞](https://blog.csdn.net/q7w8e9r4/article/details/134919387?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-134919387-blog-134675467.235^v43^pc_blog_bottom_relevance_base6&spm=1001.2101.3001.4242.1&utm_relevant_index=1)