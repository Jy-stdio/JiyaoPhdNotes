#! https://zhuanlan.zhihu.com/p/679395822
# 【Paper Reading】Foundation model | 可解释性 | 图像融合 20240123 

# **Foundational Models in Medical Imaging: A Comprehensive Survey and Future Vision**

本文介绍了介绍了Foundation model在医学影像领域的一些应用，比较全面的总结了FM的临床重要性（多模态、可解释可泛化、隐私保护、Domain knowledge等），并将现有的工作分类为通用、混合、对比、生成式、微调、适配等类型。接着介绍了FM的一些基础知识，包括目标函数、训练策略、指令对齐、prompt engineering，并介绍了各个方面的应用等。

> Paper: https://arxiv.org/abs/2310.18689
>
> Github: https://github.com/xmindflow/Awesome-Foundation-Models-in-Medical-Imaging

## Introduction

Pretrained foundation model

+ **Textually Prompted Models (TPMs)**

+ **Visually Prompted Models (VPMs)**: points, boxes, masks

Application of foundation model 

+ Adapted to a wide range of downstream tasks

Medical Foundation Model (MFM)

+ Adaptively interpret various medical modalities, including diverse data sources such as images, electronic medical records

### **Clinical Importance**

+ **Multi-Modality:** real-world applicability.
+ **Explainability and Generalization:** the ability of models to generalize across different medical settings
+ **Privacy Preservation**: foundation models facilitate privacy preservation by generating synthetic data resembling real medical images
+ **Adaptability:**  MFMs can effectively adapt to distribution shifts through in-context learning. For instance, a hospital can teach an MFM model to interpret X-rays from a new scanner by providing a few examples as prompts, enabling it to adjust to new data distributions in real-time.
+ **Domain Knowledge:** MFMs can integrate formal medical knowledge from existing databases

![](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/image-20240117150656276.png)

![](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/image-20240117151818426.png)

##  **Preliminaries**

###  **Pre-training Objectives**

###   **Pre-training Tasks**

### **Instruction-Aligning**

### **Prompt Engineering**

##  **Foundational Models for Medical Imaging**

### **Textually Prompted Models**

###  ==**Visually Prompted Models**==

#### ==**Adaptations** (task-specific adaptability)==

The adaptations and modifications made to traditional segmentation models, enhance their specificity and performance for medical imaging tasks. Figure 5 is the  Medical SAM Adapter, which bridges the gap and enhances SAM’s performance in the medical domain.

![](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/image-20240117153127708.png)

#### ==**Generalist**==

Definition:  designed to encompass a broader spectrum of tasks and data modalities.

![](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/image-20240117153548186.png)

---

# Less is More: Fewer Interpretable Region via Submodular Subset Selection

图像归因算法是一种典型的可解释方法产生显著性图，解释哪些图像区域对模型决策更重要。本文解决了当前SOTA[归因算法](https://www.zhihu.com/search?q=归因算法&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A3367218717})的两个**挑战**：1）现有的归因方法生成不准确的小区域，从而误导了正确归因的方向；2）模型无法对错误预测的样本产生良好的归因结果。

> + **ICLR 2024 Oral, 得分6888**
> + Paper：https://openreview.net/forum?id=jKTUlxo5zy
> + Biog：https://www.zhihu.com/question/639592374/answer/3367218717?utm_campaign=shareopn&utm_content=group3_Answer&utm_medium=social&utm_oi=998216950467743744&utm_psn=1731791565951979520&utm_source=wechat_session
> + github: https://github.com/RuoyuChen10/SMDL-Attribution?tab=readme-ov-file

![](https://github.com/RuoyuChen10/SMDL-Attribution/blob/main/image/abstract.gif)

![](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/02q2n7.png)

![](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/image-20240120010105495.png)

---

# CDDFuse: Correlation-Driven Dual-Branch Feature Decomposition**for Multi-Modality Image Fusion**

摘要：多模态图像融合旨在融合多模态图像并保留不同模态的优势（特殊细节和纹理）。本文旨在解决图像融合中跨模态特征建模和模态特有/共享特征的解耦，提出了**关联驱动的特征解耦融合网络**（ *Correlation-Driven feature Decompo* *sition Fusion (CDDFuse) network*）。

> ① CDDFuse 使用Restormer blocks提取跨模态浅层特征；
>
> ②接着使用dual-branch transformer-cnn提取全局低频特征；使用可逆神经网络提取局部高频信息（利用INN无损信息保留的特性）；
>
> ③ 使用*correlation* *driven loss* 使得不同模态的低频特征相关，高频特征无关。
>
> ④ 接着使用LT-based global fusion和*INN-based local fusion*分别融合。

> Paper: **CVPR, 2023**
>
> Code: https://github.com/Zhaozixiang1228/MMIF-CDDFuse

![](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/T1WbC5.png)

![](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/Mh9z1L.png)

实验结果：

![](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/image-20240121213140825.png)

![](https://ossjiyaoliu.oss-cn-beijing.aliyuncs.com/uPic/image-20240121213217635.png)



